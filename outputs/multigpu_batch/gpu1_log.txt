/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
2025-12-11 22:37:06 | INFO     | ================================================================================
2025-12-11 22:37:06 | INFO     | BATCH CONFIGURATION
2025-12-11 22:37:06 | INFO     | ================================================================================
2025-12-11 22:37:06 | INFO     | Tasks: 3
2025-12-11 22:37:06 | INFO     | EACPS: K_global=8, M=3, K_local=4
2025-12-11 22:37:06 | INFO     | Candidates per run: 20
2025-12-11 22:37:06 | INFO     | Runs per task: 2 (dual output)
2025-12-11 22:37:06 | INFO     | Gemini calls per task: 40
2025-12-11 22:37:06 | INFO     | TOTAL expected Gemini calls: 120
2025-12-11 22:37:06 | INFO     | Moondream: ENABLED
2025-12-11 22:37:06 | INFO     | Estimated Gemini cost: $0.45
2025-12-11 22:37:06 | INFO     | ================================================================================
2025-12-11 22:37:06 | INFO     | Initializing models...
Batch Progress:   0%|          | 0/3 [00:00<?, ?task/s]2025-12-11 22:37:06 | INFO     | 
================================================================================
2025-12-11 22:37:06 | INFO     | TASK 1/3: 71650389
2025-12-11 22:37:06 | INFO     | ================================================================================
2025-12-11 22:37:06 | INFO     | ================================================================================
2025-12-11 22:37:06 | INFO     | Task 71650389: Ishwar Singh
2025-12-11 22:37:06 | INFO     | ================================================================================
Task 71650389 - Init hair:   0%|          | 0/3 [00:00<?, ?task/s]2025-12-11 22:37:06 | INFO     | ðŸŽ¨ VERSION 1: Init hair preservation
2025-12-11 22:37:07 | INFO     | Loading InsightFace models...
2025-12-11 22:37:10 | INFO     | InsightFace models loaded
2025-12-11 22:37:10 | INFO     | Face swap: source bbox=[201, 127, 464, 478], target bbox=[250, 139, 411, 366]
2025-12-11 22:37:12 | INFO     | Face detected at (105, 57, 466, 466)
/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.
  warnings.warn(message, FutureWarning)
2025-12-11 22:37:12 | INFO     | Gemini client initialized with models/gemini-2.5-pro
2025-12-11 22:37:28 | INFO     | Loading Moondream V3 from vikhyatk/moondream2...
`torch_dtype` is deprecated! Use `dtype` instead!
2025-12-11 22:37:31 | INFO     | Moondream V3 loaded
2025-12-11 22:37:32 | INFO     | Loading Qwen/Qwen-Image-Edit on cuda:1...
  Stage 0: InsightFace face swap
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
find model: /home/srinivas/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
find model: /home/srinivas/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
find model: /home/srinivas/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
find model: /home/srinivas/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
find model: /home/srinivas/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5
set det-size: (640, 640)
Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}
inswapper-shape: [1, 3, 128, 128]
    Face swap successful
  Stage 1: Global exploration (8 candidates)
    Raw face swap: Potential=48.50
    Generating candidate 1/8 (seed=5000)...

Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s][A

Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Loading checkpoint shards:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [00:00<00:00, 70.00it/s][A[ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 73.78it/s]

Loading pipeline components...:  17%|â–ˆâ–‹        | 1/6 [00:00<00:01,  4.91it/s][A
Loading pipeline components...:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:00<00:01,  2.60it/s][A`torch_dtype` is deprecated! Use `dtype` instead!


Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][A[ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 84.73it/s]

Loading pipeline components...:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 5/6 [00:00<00:00,  7.26it/s][ALoading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.28it/s]
2025-12-11 22:37:35 | ERROR    | Failed task 71650389: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 63.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.14 GiB memory in use. Of the allocated memory 16.38 GiB is allocated by PyTorch, and 178.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 316, in main
    result = process_task_dual(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 124, in process_task_dual
    best_init_hair, candidates_init = run_eacps_inpaint(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 515, in run_eacps_inpaint
    raw_result = qwen_pipe.generate(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 316, in generate
    pipe = self._load()
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 300, in _load
    self._pipe.to(self.device)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py", line 545, in to
    module.to(device, dtype)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1340, in to
    return self._apply(convert)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 900, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 927, in _apply
    param_applied = fn(param)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1326, in convert
    return t.to(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 130.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 63.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.14 GiB memory in use. Of the allocated memory 16.38 GiB is allocated by PyTorch, and 178.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Task 71650389 - Init hair:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:29<00:58, 29.08s/task]2025-12-11 22:37:35 | INFO     | 
================================================================================
2025-12-11 22:37:35 | INFO     | TASK 2/3: 71634650
2025-12-11 22:37:35 | INFO     | ================================================================================
2025-12-11 22:37:35 | INFO     | ================================================================================
2025-12-11 22:37:35 | INFO     | Task 71634650: Samiksha Singh
2025-12-11 22:37:35 | INFO     | ================================================================================
Task 71634650 - Init hair:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:29<00:58, 29.08s/task]2025-12-11 22:37:35 | INFO     | ðŸŽ¨ VERSION 1: Init hair preservation
2025-12-11 22:37:35 | INFO     | Face swap: source bbox=[299, 96, 371, 198], target bbox=[187, 109, 403, 427]
2025-12-11 22:37:35 | INFO     | Face detected at (275, 85, 126, 126)
2025-12-11 22:37:54 | ERROR    | Moondream identity scoring failed: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 11.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.19 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 193.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/scorers.py", line 186, in score_identity
    enc_result = model.encode_image(result_image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 249, in encode_image
    img_emb = self._run_vision_encoder(image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 211, in _run_vision_encoder
    outputs = self._vis_enc(all_crops)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 169, in _vis_enc
    return vision_encoder(x, self.vision, self.config.vision)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/vision.py", line 70, in vision_encoder
    x = x + attn(layer_norm(x, block.ln1), block.attn, n_heads=config.enc_n_heads)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 161, in attn
    for t in linear(x, w.qkv).chunk(3, dim=-1)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 35, in linear
    return F.linear(x, w.weight, w.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 11.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.19 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 193.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-11 22:37:54 | ERROR    | Moondream realism scoring failed: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 11.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.19 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 193.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/scorers.py", line 235, in score_realism
    enc_result = model.encode_image(result_image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 249, in encode_image
    img_emb = self._run_vision_encoder(image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 211, in _run_vision_encoder
    outputs = self._vis_enc(all_crops)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 169, in _vis_enc
    return vision_encoder(x, self.vision, self.config.vision)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/vision.py", line 70, in vision_encoder
    x = x + attn(layer_norm(x, block.ln1), block.attn, n_heads=config.enc_n_heads)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 161, in attn
    for t in linear(x, w.qkv).chunk(3, dim=-1)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 35, in linear
    return F.linear(x, w.weight, w.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 11.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.19 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 193.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-11 22:37:54 | ERROR    | Failed task 71634650: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 188.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 316, in main
    result = process_task_dual(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 124, in process_task_dual
    best_init_hair, candidates_init = run_eacps_inpaint(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 515, in run_eacps_inpaint
    raw_result = qwen_pipe.generate(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 324, in generate
    result = pipe(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 719, in __call__
    prompt_embeds, prompt_embeds_mask = self.encode_prompt(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 304, in encode_prompt
    prompt_embeds, prompt_embeds_mask = self._get_qwen_prompt_embeds(prompt, image, device)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 249, in _get_qwen_prompt_embeds
    outputs = self.text_encoder(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1476, in forward
    outputs = self.model(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1257, in forward
    image_embeds = self.get_image_features(pixel_values, image_grid_thw)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1170, in get_image_features
    image_embeds = self.visual(pixel_values, grid_thw=image_grid_thw)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 417, in forward
    hidden_states = self.patch_embed(hidden_states)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 89, in forward
    hidden_states = self.proj(hidden_states.to(dtype=target_dtype)).view(-1, self.embed_dim)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 725, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 720, in _conv_forward
    return F.conv3d(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 188.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Task 71634650 - Init hair:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:48<00:23, 23.29s/task]2025-12-11 22:37:54 | INFO     | 
================================================================================
2025-12-11 22:37:54 | INFO     | TASK 3/3: 71673477
2025-12-11 22:37:54 | INFO     | ================================================================================
2025-12-11 22:37:54 | INFO     | ================================================================================
2025-12-11 22:37:54 | INFO     | Task 71673477: Ashwin
2025-12-11 22:37:54 | INFO     | ================================================================================
Task 71673477 - Init hair:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:48<00:23, 23.29s/task]2025-12-11 22:37:54 | INFO     | ðŸŽ¨ VERSION 1: Init hair preservation
2025-12-11 22:37:54 | INFO     | Face swap: source bbox=[99, 202, 476, 773], target bbox=[694, 724, 814, 887]
2025-12-11 22:37:55 | INFO     | Face detected at (0, 141, 576, 647)
2025-12-11 22:38:13 | ERROR    | Moondream identity scoring failed: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 197.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/scorers.py", line 186, in score_identity
    enc_result = model.encode_image(result_image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 249, in encode_image
    img_emb = self._run_vision_encoder(image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 211, in _run_vision_encoder
    outputs = self._vis_enc(all_crops)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 169, in _vis_enc
    return vision_encoder(x, self.vision, self.config.vision)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/vision.py", line 70, in vision_encoder
    x = x + attn(layer_norm(x, block.ln1), block.attn, n_heads=config.enc_n_heads)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 161, in attn
    for t in linear(x, w.qkv).chunk(3, dim=-1)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 35, in linear
    return F.linear(x, w.weight, w.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 197.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-11 22:38:13 | ERROR    | Moondream realism scoring failed: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 197.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/scorers.py", line 235, in score_realism
    enc_result = model.encode_image(result_image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 249, in encode_image
    img_emb = self._run_vision_encoder(image)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 211, in _run_vision_encoder
    outputs = self._vis_enc(all_crops)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/moondream.py", line 169, in _vis_enc
    return vision_encoder(x, self.vision, self.config.vision)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/vision.py", line 70, in vision_encoder
    x = x + attn(layer_norm(x, block.ln1), block.attn, n_heads=config.enc_n_heads)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 161, in attn
    for t in linear(x, w.qkv).chunk(3, dim=-1)
  File "/home/srinivas/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/6b714b26eea5cbd9f31e4edb2541c170afa935ba/layers.py", line 35, in linear
    return F.linear(x, w.weight, w.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.42 GiB is allocated by PyTorch, and 197.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-12-11 22:38:13 | ERROR    | Failed task 71673477: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 188.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 316, in main
    result = process_task_dual(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/run_batch_dual.py", line 124, in process_task_dual
    best_init_hair, candidates_init = run_eacps_inpaint(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 515, in run_eacps_inpaint
    raw_result = qwen_pipe.generate(
  File "/mnt/data1/srini/qwen3-score/inpaint_eacps/pipeline.py", line 324, in generate
    result = pipe(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 719, in __call__
    prompt_embeds, prompt_embeds_mask = self.encode_prompt(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 304, in encode_prompt
    prompt_embeds, prompt_embeds_mask = self._get_qwen_prompt_embeds(prompt, image, device)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/diffusers/pipelines/qwenimage/pipeline_qwenimage_edit.py", line 249, in _get_qwen_prompt_embeds
    outputs = self.text_encoder(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 918, in wrapper
    output = func(self, *args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1476, in forward
    outputs = self.model(
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1257, in forward
    image_embeds = self.get_image_features(pixel_values, image_grid_thw)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1170, in get_image_features
    image_embeds = self.visual(pixel_values, grid_thw=image_grid_thw)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 417, in forward
    hidden_states = self.patch_embed(hidden_states)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 89, in forward
    hidden_states = self.proj(hidden_states.to(dtype=target_dtype)).view(-1, self.embed_dim)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 725, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/mnt/data1/srini/qwen3-score/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 720, in _conv_forward
    return F.conv3d(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 79.19 GiB of which 7.69 MiB is free. Process 709369 has 61.96 GiB memory in use. Including non-PyTorch memory, this process has 17.20 GiB memory in use. Of the allocated memory 16.43 GiB is allocated by PyTorch, and 188.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Task 71673477 - Init hair: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:07<00:00, 21.48s/task]Task 71673477 - Init hair: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:07<00:00, 22.55s/task]
2025-12-11 22:38:13 | INFO     | 
================================================================================
2025-12-11 22:38:13 | INFO     | BATCH COMPLETE
2025-12-11 22:38:13 | INFO     | ================================================================================
2025-12-11 22:38:13 | INFO     | Processed: 0/3 tasks
2025-12-11 22:38:13 | INFO     | Total Gemini API calls: 0
2025-12-11 22:38:13 | INFO     | Actual cost: $0.00
2025-12-11 22:38:13 | INFO     | Total time: 0:01:07.652378
2025-12-11 22:38:13 | INFO     | Output directory: outputs/multigpu_batch/gpu1
2025-12-11 22:38:13 | INFO     | Summary saved: outputs/multigpu_batch/gpu1/batch_summary.json
  Stage 0: InsightFace face swap
    Face swap successful
  Stage 1: Global exploration (8 candidates)
    Raw face swap: Potential=36.50
    Generating candidate 1/8 (seed=5000)...
  Stage 0: InsightFace face swap
    Face swap successful
  Stage 1: Global exploration (8 candidates)
    Raw face swap: Potential=39.50
    Generating candidate 1/8 (seed=5000)...
